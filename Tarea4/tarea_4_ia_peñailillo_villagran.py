# -*- coding: utf-8 -*-
"""Tarea-4-IA-Peñailillo-Villagran.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n9u2XiDzEj2rYWervFYEauTuNlwHo0bo

## Configuraciones previas
Para poder resolver los problemas planteados en el enunciado se deben realizar ciertos ajustes y preparaciones en el entorno de ejecución, como por ejemplo la llamada a las librerias de Python y la inclusión del dataset a trabajar.

Para una ejecución más veloz se recomienda habilitar el tipo de entorno enfocado en GPU en las configuraciones de Colab.
"""

!pip install -q kaggle

from google.colab import files
uploaded = files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d jeffheaton/iris-computer-vision
! unzip /content/iris-computer-vision.zip

import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers
from time import perf_counter 
import os

"""## Clasificación"""

batch_size = 10
img_height = 224
img_width = 224

"""Para lograr el correcto funcionamiento de la red neuronal se debe crear una carpeta de nombre iris que contenga a las carpetas iris-setosa, iris-versicolour y iris-virginica pertenecientes al dataset."""

!mkdir iris
!mv iris-setosa/ iris/iris-setosa/ 
!mv iris-versicolour/ iris/iris-versicolour/
!mv iris-virginica/ iris/iris-virginica/

"""Se prepara el conjunto de datos de entrenamiento."""

training_ds = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/iris',
    validation_split=0.2,
    subset= "training",
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size
)

"""Se prepara el conjunto de datos de validación."""

validation_ds = tf.keras.preprocessing.image_dataset_from_directory(
'/content/iris',
    validation_split=0.2,
    subset= "validation",
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size
)

class_names = training_ds.class_names

AUTOTUNE = tf.data.experimental.AUTOTUNE
training_ds = training_ds.cache().prefetch(buffer_size=AUTOTUNE)
validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)

"""Se definen las capas de la Red Neuronal Convolucional a usar para la clasificación de las imágenes."""

MyCnn = tf.keras.models.Sequential([
  layers.BatchNormalization(),
  layers.Conv2D(32, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(128, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(256, activation='relu'),
  layers.Dense(len(class_names), activation= 'softmax')
])

MyCnn.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])

"""Se realiza el entrenamiento de la red."""

retVal = MyCnn.fit(training_ds,validation_data= validation_ds,epochs = 5)

"""Se realizan los gráficos y la comparación de la etiqueta clasificada con la etiqueta real."""

plt.figure(figsize=(30, 10))
for images, labels in validation_ds.take(1):
    predictions = MyCnn.predict(images)
    predlabel = []
    prdlbl = []
    
    for mem in predictions:
        predlabel.append(class_names[np.argmax(mem)])
        prdlbl.append(np.argmax(mem))
    
    AccuracyVector = np.array(prdlbl) == labels
    for i in range(10):
        ax = plt.subplot(2, 5, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title('Pred: '+ predlabel[i]+' actl: '+class_names[labels[i]] )
        plt.axis('off')
        plt.grid(True)

"""Se realizan gráficos de la precisión y la perdida asociada al dataset y a la clasificación llevada a cabo, tanto para el caso de entrenamiento como para la validación."""

plt.plot(retVal.history['loss'], label = 'training loss')
plt.plot(retVal.history['val_loss'], label = 'validation loss')
plt.legend()

plt.plot(retVal.history['accuracy'], label = 'training accuracy')
plt.plot(retVal.history['val_accuracy'], label = 'validation accuracy')
plt.legend()

"""## Análisis
Como principales métricas de error se tienen la perdida tanto en el conjunto de entrenamiento como en el de validación, esto puede verse reflejado en su respectivo gráfico y representa lo "cerca" que se puede estar a caer en un estado de *overfitting* o *underfitting*. En cuanto a la evolución de la calidad de la red, esta puede verse reflejada en la tendencia al aumento de la métrica de precisión para ambas secciones del dataset. Si se analizan los hiper-parámetros de inicio utilizados se tiene que la cantidad de iteraciones (*epochs*) a realizar no debe superar las 5 ya que en caso contrario segun el modelo planteado se llega a un estado de *overfitting*. De manera similar se puede analizar la cantidad de fotos a mostrar como resultado parcial de la ejecución, dicho valor (*batch_size*) es inicializado en 10 para ahorrar recursos de procesamiento gráfico y enfocar su uso en la tarea de clasificación.

## Predicción

Para la realización de esta sección de la tarea se debe trabajar con otro dataset, el cual incluye datos sobre el sépalo y el pétalo de las flores, además de su respectiva foto. Dicho dataset es el resultante de la mezcla manual de los ya publicados en kaggle.
"""

! kaggle datasets download -d uciml/iris
! unzip /content/iris.zip

!pip install -U pandasql 
from pandasql import sqldf
from os import listdir

data = pd.read_csv("Iris.csv")

cont = 0
cont2 = 0
cont3 = 0
folder_dir = "iris/iris-setosa"
folder_dir2 = "iris/iris-versicolour"
folder_dir3 = "iris/iris-virginica"
path_list = []

for images in os.listdir(folder_dir):
  while cont < 50:
    if (images.endswith(".jpg")):
        path = folder_dir + "/" + images
        path_list.append(path)
        cont += 1

for images in os.listdir(folder_dir2):
  while cont2 < 50:
    if (images.endswith(".jpg")):
        path2 = folder_dir2 + "/" + images
        path_list.append(path2)
        cont2 += 1

for images in os.listdir(folder_dir3):
  while cont3 < 50:
    if (images.endswith(".jpg")):
        path3 = folder_dir3 + "/" + images
        path_list.append(path3)
        cont3 += 1

data['Path'] = path_list
data.head()

"""Se realiza la separación del dataset en las secciones de training y testing."""

q="SELECT *, Id%10 as grup FROM data WHERE grup = 0 OR grup= 1 OR grup = 2 OR grup = 3 OR grup = 7 OR grup = 8 OR grup = 9 OR grup= 4 OR grup= 5  "
TrainingData = sqldf(q,globals())

q="SELECT *, Id%10 as grup FROM data WHERE grup= 6  "
TestingData = sqldf(q,globals())

print(TrainingData.shape)
print(TestingData.shape)

"""Luego de crear y preparar el dataset se incluyen las librerias necesarias para la resolución del problema planteado."""

import numpy as np
import pandas as pd
from pathlib import Path
import os.path

from sklearn.model_selection import train_test_split

import tensorflow as tf

from sklearn.metrics import r2_score

"""Se generan las configuraciones necesarias para el funcionamiento de la Red Neuronal Convolucional."""

train_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    validation_split=0.223
)

test_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255
)

train_images = train_generator.flow_from_dataframe(
    dataframe=TrainingData,
    x_col='Path',
    y_col=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'],
    target_size=(120, 120),
    color_mode='rgb',
    class_mode='raw',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images = train_generator.flow_from_dataframe(
    dataframe=TrainingData,
    x_col='Path',
    y_col=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'],
    target_size=(120, 120),
    color_mode='rgb',
    class_mode='raw',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images = test_generator.flow_from_dataframe(
    dataframe=TestingData,
    x_col='Path',
    y_col=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'],
    target_size=(120, 120),
    color_mode='rgb',
    class_mode='raw',
    batch_size=32,
    shuffle=False
)

"""Se genera la estructura de capas de la red a usar para la predicción de parámetros."""

inputs = tf.keras.Input(shape=(120, 120, 3))
x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)
x = tf.keras.layers.MaxPool2D()(x)
x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)
x = tf.keras.layers.MaxPool2D()(x)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(64, activation='relu')(x)
x = tf.keras.layers.Dense(64, activation='relu')(x)
outputs = tf.keras.layers.Dense(4, activation='linear')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer='adam',
    loss='mse',
    metrics=['accuracy']
)

history = model.fit(
    train_images,
    validation_data=val_images,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )
    ]
)

"""Se muestran las predicciones y se comparan con los parámetros reales mediante el uso del error cuadrático medio."""

predicted_params = np.squeeze(model.predict(test_images))
true_params = test_images.labels

print(predicted_params)
print("----------------------------------------------")
print(true_params)
print("----------------------------------------------")
rmse = np.sqrt(model.evaluate(test_images, verbose=0))
print(list(map("RMSE: {:.5f}".format, rmse)))

"""## Análisis
En lo relativo a las métricas de error en este caso, se utiliza el error cuadrático medio, sin embargo se presentaron algunos problemas de implementación que causaron una ligera falla en el calculo y representación de la métrica tratada dado que se esperaban cuatro valores distintos (uno por cada parámetro a analizar) pero solo se obtuvieron dos valores. Con respecto a la evolución de la calidad de la red se puede notar que, al observar la métrica de precisión, el modelo salta a un valor de 1 tras pocas iteraciones lo cual puede deberse al reducido tamaño del dataset usado, aún así los datos predichos por la red se acercan de manera aceptable a los datos reales. Si se analizan los hiper-parámetros de inicio utilizados se puede notar que en comparación con el ejercicio de clasificación, para realizar predicciones son necesarias más iteraciones con el objetivo de lograr una mayor cercanía entre los datos predichos y los datos reales. De manera similar, se puede analizar el *batch_size*, este parámetro corresponde a la cantidad de imágenes que la red analiza por cada iteración y su valor corresponde a 32, siendo mayor al usado en la clasificación debido al mayor requerimiento de información para predecir valores de forma eficiente.
"""
# -*- coding: utf-8 -*-
"""Tarea-3-IA-Peñailillo-Villagran.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qHmCUwa6pcQSZw1NhkWg-pCuF_Gkdq-Q

## **Configuraciones previas e Instalación de librerías y paquetes**

En primer lugar se requiere realizar diversos ajustes al entorno de ejecución, dichos ajustes pueden observarse a continuación:
"""

!pip install -q kaggle

from google.colab import files
uploaded = files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d patrickgendotti/steam-achievementstatscom-rankings
! unzip /content/steam-achievementstatscom-rankings.zip

"""Tras haber realizado los ajustes mencionados, se requiere instalar distintas librerías y paquetes de Python para poder llevar a cabo la resolución de los problemas planteados en el enunciado, dichas librerías y paquetes son instalados a continuación:"""

!pip install -U matplotlib
import matplotlib as plt
import pandas as pd
import numpy as np

!pip install -U pandasql 
from pandasql import sqldf
from sklearn import datasets

!pip install -U scikit-learn
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LinearRegression
from sklearn.cluster import DBSCAN
from sklearn.mixture import GaussianMixture
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import max_error

"""## **Lectura de datos**
Para esta sección del desarrollo de la tarea se usa la librería *pandas* y su función *read_csv()* para obtener los datos del dataset y guardarlos en una variable, esta variable es de tipo dataframe lo cual nos otorga distintas facilidades al momento de trabajarla.

La función *describe()* nos entrega diversas estadisticas del dataframe deseado, mientras que la función *head()* nos muestra las primeras lineas del dataframe.
"""

data = pd.read_csv("amended_first_200k_players.csv")
data.describe()

data.head()

"""## **Distribución de datos para Training y Testing**
Mediante el uso de la librería *pandasql* se crean dos consultas para poder separar el dataset en una proporción de 60% para training y 40% para testing. Posteriormente se definen los campos del dataset a tratar por los distintos algoritmos y se indican las dimensiones de cada sección del dataset.
"""

q="SELECT *, Rank%5 as grup FROM data WHERE grup = 0 OR grup= 2 OR grup = 4  "
TrainingData = sqldf(q,globals())

q="SELECT *, Rank%5 as grup FROM data WHERE grup = 1 OR grup= 3  "
TestingData = sqldf(q,globals())

inputTrainingX = np.array(TrainingData[['Games','Badges','100%']])
inputTrainingY = np.array(TrainingData[['Points']])
inputTestingX = np.array(TestingData[['Games','Badges','100%']])
inputTestingY = np.array(TestingData[['Points']])

print(inputTrainingX.shape)
print(inputTrainingY.shape)
print(inputTestingX.shape)
print(inputTestingY.shape)

"""## **Visualización de datos**
A continuación se muestra un gráfico de los datos de entrenamiento en su estado natural, sin ser afectados por ninguno de los algoritmos a desarrollar. Además puede observarse la cantidad de usuarios y su respectiva cantidad de juegos, medallas, juegos completados al 100% y puntos de Steam gracias al uso de la función *groupby()*.
"""

plt.scatter(inputTrainingX[:,0], inputTrainingY)
plt.show

print(TrainingData.groupby('Games').size())
print("--------------------------------------------")
print(TrainingData.groupby('Badges').size())
print("--------------------------------------------")
print(TrainingData.groupby('100%').size())
print("--------------------------------------------")
print(TrainingData.groupby('Points').size())

"""## **Algoritmo KNN**
Este algoritmo predice el valor de los puntos de Steam de cada usuario según los valores de los usuarios que lo rodean. Se puede observar tambien el cálculo del error haciendo uso de 3 métricas distintas según lo solicitado en el enunciado. Dichas métricas otorgan mediciones del error muy distintas entre si, lo cual puede explicarse debido a las fórmulas matematicas de donde provienen. La métrica que otorga un mejor valor de error en relación a los datos de la predicción resulta ser el error absoluto medio.

Finalmente se puede observar una comparación entre 2 gráficos que representan los datos de testing y la predicción realizada respectivamente, resulta evidente la diferencia entre los valores obtenidos en ambos casos sin embargo cabe destacar la buena aproximación lograda por la predicción.
"""

neigh = KNeighborsRegressor(n_neighbors=10)
neigh.fit(inputTrainingX, inputTrainingY)
print(neigh.predict(inputTestingX))
res = neigh.predict(inputTestingX)

print("error cuadrático medio: ", mean_squared_error(inputTestingY, res))
print("error absoluto medio: ", mean_absolute_error(inputTestingY, res))
print("error máximo residual: ", max_error(inputTestingY, res))

plt.figure(0)
plt.plot(inputTestingY)
plt.grid()
plt.title('Datos de Testing')
plt.xlabel('Testing')
plt.ylabel('Training')
plt.figure(1)
plt.plot(res)
plt.grid()
plt.title('Datos de la Predicción')
plt.xlabel('Testing')
plt.ylabel('Training')
plt.show

"""## **Algoritmo Regresión Lineal**
Este algoritmo predice el valor de los puntos de Steam de cada usuario según la cercanía que tenga dicho usuario a una recta de ajuste lineal. En el caso del dataset utilizado y los campos elegidos dicha recta es generada mayormente por el campo "100%" (el cual puede ser observado en el tercer gráfico de puntos) sin embargo la densidad de puntos en los otros dos campos genera una perdida de precisión que dificulta llevar a cabo una buena predicción, esto puede verse reflejado en el alto valor del error si se le compara con los datos obtenidos de la predicción. Se puede notar además como el valor obtenido mediante el uso del error cuadrático medio se acerca al obtenido para el caso de KNN bajo la misma métrica, lo cual se explica en que se está trabajando con los mismos datos en ambos casos.
"""

reg = LinearRegression().fit(inputTrainingX, inputTrainingY)
print(reg.predict(inputTestingX))
res2 = reg.predict(inputTestingX)

print("error cuadrático medio: ", mean_squared_error(inputTestingY, res2))

plt.figure(0)
plt.scatter(inputTestingX[:,0],res2)
plt.xlabel('Testing')
plt.ylabel('Training')
plt.figure(1)
plt.scatter(inputTestingX[:,1],res2)
plt.xlabel('Testing')
plt.ylabel('Training')
plt.figure(2)
plt.scatter(inputTestingX[:,2],res2)
plt.xlabel('Testing')
plt.ylabel('Training')
plt.show

plt.plot(inputTestingX[:,2],res2)
plt.xlabel('Testing')
plt.ylabel('Training')
plt.legend(['inputTesting','resultados'])
plt.grid()
plt.show

"""## **Algoritmo GMM**
En este algoritmo se espera clasificar los datos entregados como parámetros de aprendizaje (Games, Badges y 100%) e identificar cual es el que aporta más a la predicción del parámetro Points. Como se puede observar en los distintos gráficos generados es claro que el parámetro de etiqueta con valor 2 es quien más aporta de cara a la predicción, dicho parámetro corresponde a la cantidad de juegos que el usuario haya completado al 100%. Esta interpretación de los datos obtenidos se sustenta en como se definieron anteriormente las variables *inputTrainingX* y *inputTestingX* en la sección de distribución de datos.
"""

gm = GaussianMixture(n_components=3, covariance_type="full", init_params="kmeans").fit(inputTrainingX, inputTrainingY)
gm.means_
res3 = gm.predict(inputTestingX)
print(res3)

plt.figure(0)
plt.scatter(inputTestingX[:,0], res3)
plt.figure(1)
plt.scatter(inputTestingX[:,1], res3)
plt.figure(2)
plt.scatter(inputTestingX[:,2], res3)
plt.figure(3)
plt.scatter(inputTestingY, res3)
plt.show

"""## **Algoritmo DBSCAN**
De manera similar al caso anterior, en este algoritmo se espera clasificar los datos entregados como parámetros de aprendizaje (Games, Badges y 100%) e identificar cual es el que aporta más a la predicción del parámetro Points. Como se puede observar en los distintos gráficos generados es claro que el parámetro de etiqueta con valor -1 es quien más aporta de cara a la predicción, sin embargo resulta dificil asociar dicho parámetro a uno de los campos antes mencionados. Se presume que corresponda al campo "100%" ya que la lógica de funcionamiento de ambos algoritmos es similar, por lo que deberian entregar resultados similares hasta cierto punto, guardando las proporciones generadas por los detalles de funcionamiento en cada caso.
"""

dbs = DBSCAN(eps=25, min_samples=25).fit(inputTrainingX, inputTrainingY)
res4 = dbs.fit_predict(inputTestingX, inputTestingY)
print(dbs.labels_)

plt.figure(0)
plt.scatter(inputTestingX[:,0], res4, c = dbs.labels_.astype(float), s = 50)
plt.figure(1)
plt.scatter(inputTestingX[:,1], res4, c = dbs.labels_.astype(float), s = 50)
plt.figure(2)
plt.scatter(inputTestingX[:,2], res4, c = dbs.labels_.astype(float), s = 50)
plt.figure(3)
plt.scatter(inputTestingY, res4, c = dbs.labels_.astype(float), s = 50)
plt.show

"""## **Comparación entre GMM y DBSCAN**
Cabe destacar que ambos algoritmos predicen 3 valores distintos para las etiquetas, lo cual se asocia directamente con la naturaleza del problema planteado. 

Una diferencia importante a notar es el hecho de que DBSCAN puede utilizar valores negativos para indicar las etiquetas obtenidas mientras que GMM solo utiliza valores mayores o iguales a cero. Otra diferecia destacable es el hecho de que GMM puede trabajar con una mezcla de distribuciones de datos (tanto visibles como ocultos) gracias al uso del algoritmo EM, mientras que DBSCAN solo trabaja sobre una distribución de datos los cuales deben ser explicitos para poder ser utilizados.
"""